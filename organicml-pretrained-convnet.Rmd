---
title: "Organic ML Pretrained Convnet"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load the libraries

```{r}
library(keras)
library(ramify)
```

## Define where the image datasets are

There is a small dataset of 410 images. They are split like this:

|dataset|benzene ring images|non benzene ring images
|---|---|---|
|train|125|125|
|validation|25|25|
|test|55|55|

```{r}
train_dir <- "data/train"
validation_dir <- "data/validation"
test_dir <- "data/test"
```

## Create the image generators

Use data augmentation on the training set, but not the validation set.

```{r warning=FALSE}
test_validation_batch_size <- 25

validation_datagen <- image_data_generator(rescale = 1/255)

train_datagen <- image_data_generator(
  rescale = 1/255,
  rotation_range = 40,
  width_shift_range = 0.2,
  height_shift_range = 0.2,
  shear_range = 0.2,
  zoom_range = 0.2,
  horizontal_flip = TRUE
)

train_generator <- flow_images_from_directory(
  train_dir,
  train_datagen,
  target_size = c(256, 256),
  batch_size = test_validation_batch_size,
  class_mode = "binary"
)

validation_generator <- flow_images_from_directory(
  validation_dir,
  validation_datagen,
  target_size = c(256, 256),
  batch_size = test_validation_batch_size,
  class_mode = "binary"
)
```

## Define the network

Use VGG16 trained on imagenet for the convolutional layers. Freeze the convolutional layers so that their weights are not adjusted during training. The final layers will be a simple binary classifier made with dense layers.

```{r error=FALSE}
conv_base <- application_vgg16(
  weights = "imagenet",
  include_top = FALSE,
  input_shape = c(256, 256, 3)
)

conv_base %>% freeze_weights()

network <- keras_model_sequential() %>%
  conv_base %>%
  layer_flatten() %>%
  layer_dense(units = 256, activation = "relu") %>%
  layer_dense(units = 128, activation = "relu") %>%
  layer_dense(units = 64, activation = "relu") %>%
 layer_dense(units = 1, activation = "sigmoid")

network %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(learning_rate = 2e-5),
  metrics = c("accuracy")
)

summary(network)
```

## Fit the network using the training and validation data

The `steps_per_epoch` are calculated from the image generator batch size, according to the following StackOverflow post:

[https://stackoverflow.com/questions/60509425/how-to-use-repeat-function-when-building-data-in-keras](https://stackoverflow.com/questions/60509425/how-to-use-repeat-function-when-building-data-in-keras)


```{r error=FALSE, results='hide'}
fit_history <- network %>%
  fit(
    train_generator,
    steps_per_epoch = 250/test_validation_batch_size,
    epochs = 25,
    validation_data = validation_generator,
    validation_steps = 50/test_validation_batch_size
  )
```

## Analyze training hisotry

```{r}
plot(fit_history)
```

What epoch had the maximum validation accuracy?

```{r}
max_val_accuracy <- max(fit_history$metrics$val_accuracy)
argmax_val_accuracy <- which.max(fit_history$metrics$val_accuracy)
cat("Maximum val_accuracy: ", max_val_accuracy, "\n")
cat("Epoch of maximum validation accuracy: ", argmax_val_accuracy, "\n")
fit_history$metrics$val_accuracy[argmax_val_accuracy]
```

```{r echo=FALSE}
network %>% save_model_hdf5("convnet_and_classifier.h5")
```
